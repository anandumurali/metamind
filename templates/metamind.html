{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>METAMIND Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://kit.fontawesome.com/a2e0f5bd0a.js" crossorigin="anonymous"></script>
</head>
<body class="bg-gradient-to-br from-blue-50 via-white to-blue-100 h-screen flex flex-col font-sans">

<!-- Header -->
<header class="bg-white shadow p-4 flex justify-between items-center">
    <h1 class="text-2xl font-bold text-blue-600 flex items-center gap-2">
        ðŸ¤– METAMIND
        <span class="text-sm text-gray-500 font-normal">Your AI Assistant</span>
    </h1>
    <div class="flex items-center gap-4 text-sm text-gray-400">
        <div>
            Emotion: <span id="emotion-text" class="text-blue-600 font-semibold">Neutral</span>
        </div>
        <button id="help-btn" class="text-blue-500 hover:text-blue-700">Help</button>
    </div>
</header>

<!-- Chat Area -->
<main class="flex-1 overflow-y-auto p-6 space-y-3" id="chat-area">
    <!-- Messages will appear here -->
</main>

<!-- Input Section -->
<footer class="bg-white shadow p-4 flex items-center space-x-3">
    <button id="mic-btn" class="text-blue-600 text-xl hover:text-blue-800" title="Speak (Ctrl+M)">
        <i class="fas fa-microphone"></i>
    </button>
    <input id="user-input" type="text" placeholder="Type your message..." class="flex-1 p-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-300">
    <button id="send-btn" class="bg-blue-500 hover:bg-blue-600 text-white px-4 py-2 rounded-lg transition">Send</button>
</footer>

<!-- Help Modal -->
<div id="help-modal" class="fixed inset-0 bg-black bg-opacity-50 hidden items-center justify-center z-50">
    <div class="bg-white p-6 rounded-lg max-w-sm w-full text-gray-700 shadow-xl">
        <h2 class="text-xl font-bold text-blue-600 mb-4">How to Use METAMIND</h2>
        <ul class="list-disc pl-5 space-y-2 text-sm">
            <li>Click the <strong>microphone</strong> icon or press <kbd class="bg-gray-200 px-1 rounded">m</kbd> to activate voice input.</li>
            <li>Type your message and press <kbd class="bg-gray-200 px-1 rounded">Enter</kbd> or click <strong>Send</strong>.</li>
            <li>Your voice/text is processed and METAMIND will respond with voice + message.</li>
            <li>Facial emotion is auto-detected every 5 seconds using your webcam.</li>
            <li>Say or type "stop" to halt the voice playback.</li>
        </ul>
        <div class="mt-4 text-right">
            <button id="close-help" class="text-blue-600 hover:text-blue-800">Close</button>
        </div>
    </div>
</div>

<!-- Webcam (hidden) -->
<video id="webcam" autoplay playsinline class="hidden" width="320" height="240"></video>

<script>
    const chatArea = document.getElementById('chat-area');
    const userInput = document.getElementById('user-input');
    const sendBtn = document.getElementById('send-btn');
    const emotionText = document.getElementById('emotion-text');
    const webcam = document.getElementById('webcam');
    const micBtn = document.getElementById('mic-btn');
    const helpBtn = document.getElementById('help-btn');
    const helpModal = document.getElementById('help-modal');
    const closeHelp = document.getElementById('close-help');

    let currentEmotion = "neutral";
    let currentAudio = null;

    function addMessage(sender, text) {
        const msg = document.createElement('div');
        msg.className = `max-w-xl px-4 py-2 rounded-lg ${sender === 'user' ? 'ml-auto bg-blue-500 text-white' : 'mr-auto bg-gray-100 text-gray-800'}`;
        msg.innerText = text;
        chatArea.appendChild(msg);
        chatArea.scrollTop = chatArea.scrollHeight;
    }

    function sendMessage(message) {
    if (!message.trim()) return;

    if (message.trim().toLowerCase() === 'stop') {
        if (currentAudio) {
            currentAudio.pause();
            currentAudio.currentTime = 0;
        }

        // Speak back "Ok" using TTS from backend
        fetch('/chat/', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-CSRFToken': getCSRFToken()
            },
            body: JSON.stringify({
                message: 'Ok',
                emotion: currentEmotion
            })
        })
        .then(res => res.json())
        .then(data => {
            addMessage('bot', 'Ok');
            if (data.audio) {
                if (currentAudio) currentAudio.pause();
                currentAudio = new Audio("data:audio/mp3;base64," + data.audio);
                currentAudio.play();
            }
        });
        return;
    }

    addMessage('user', message);
    userInput.value = '';

    fetch('/chat/', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'X-CSRFToken': getCSRFToken()
        },
        body: JSON.stringify({
            message: message,
            emotion: currentEmotion
        })
    })
    .then(res => res.json())
    .then(data => {
        addMessage('bot', data.response);
        if (data.audio) {
            if (currentAudio) currentAudio.pause();
            currentAudio = new Audio("data:audio/mp3;base64," + data.audio);
            currentAudio.play();
        }
    });
}

    sendBtn.addEventListener('click', () => {
        sendMessage(userInput.value);
    });

    userInput.addEventListener('keydown', (e) => {
        if (e.key === 'Enter') {
            sendMessage(userInput.value);
        }
    });

    function getCSRFToken() {
        const cookie = document.cookie.split('; ').find(row => row.startsWith('csrftoken='));
        return cookie ? cookie.split('=')[1] : '';
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    recognition.lang = 'en-IN';
    recognition.interimResults = false;

    micBtn.addEventListener('click', () => recognition.start());

    document.addEventListener('keydown', (e) => {
        if (e.key === 'm') {
            recognition.start();
        }
    });

    recognition.onresult = event => {
        const transcript = event.results[0][0].transcript;
        sendMessage(transcript);
    };

    recognition.onerror = event => {
        console.error('Voice recognition error:', event);
    };

    helpBtn.addEventListener('click', () => helpModal.classList.remove('hidden'));
    closeHelp.addEventListener('click', () => helpModal.classList.add('hidden'));

    navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
        webcam.srcObject = stream;

        setTimeout(() => {
            const canvas = document.createElement('canvas');
            canvas.width = webcam.videoWidth;
            canvas.height = webcam.videoHeight;
            canvas.getContext('2d').drawImage(webcam, 0, 0);
            const frame = canvas.toDataURL('image/jpeg');

            fetch('/emotion/', {
                method: 'POST',
                headers: { 'X-CSRFToken': getCSRFToken() },
                body: new URLSearchParams({ frame: frame })
            })
            .then(res => res.json())
            .then(data => {
                if (data.emotion) emotionText.textContent = data.emotion;
                if (data.greeting) addMessage('bot', data.greeting);
                if (data.audio) {
                    if (currentAudio) currentAudio.pause();
                    currentAudio = new Audio("data:audio/mp3;base64," + data.audio);
                    currentAudio.play();
                }
                currentEmotion = data.emotion || 'neutral';
            });
        }, 2000);

        setInterval(() => {
            const canvas = document.createElement('canvas');
            canvas.width = webcam.videoWidth;
            canvas.height = webcam.videoHeight;
            canvas.getContext('2d').drawImage(webcam, 0, 0);
            const frame = canvas.toDataURL('image/jpeg');

            fetch('/emotion/', {
                method: 'POST',
                headers: { 'X-CSRFToken': getCSRFToken() },
                body: new URLSearchParams({ frame: frame })
            })
            .then(res => res.json())
            .then(data => {
                if (data.emotion) emotionText.textContent = data.emotion;
                currentEmotion = data.emotion || 'neutral';
            });
        }, 5000);
    });
</script>
</body>
</html>
